{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import callbacks \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='/'\n",
    "train_dir = '/home/jupyter/theSimpsons-train/train'\n",
    "test_dir = '/home/jupyter/theSimpsons-test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# rows = 17\n",
    "# cols = 6\n",
    "# fig, ax = plt.subplots(rows, cols, frameon=False, figsize=(15, 25))\n",
    "# food_dirs = os.listdir(train_dir)\n",
    "# for i in range(rows):\n",
    "#     for j in range(cols):\n",
    "#         food_dir = food_dirs[(i*cols + j)%101]\n",
    "#         all_files = os.listdir(os.path.join(train_dir, food_dir))\n",
    "#         img = plt.imread(os.path.join(train_dir, food_dir, all_files[3]))\n",
    "#         ax[i][j].imshow(img)\n",
    "#         ax[i][j].text(0, -20, food_dir, size=10, rotation=0, ha=\"left\", va=\"top\", \n",
    "#                 bbox=dict(boxstyle=\"round\", ec=(0, .6, .1), fc=(0, .7, .2)))\n",
    "# plt.setp(ax, xticks=[], yticks=[])\n",
    "# plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77575 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "data_seed = 120\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # width_shift_range=0.3,\n",
    "    # height_shift_range=0.3,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.2,\n",
    "    rotation_range=15,\n",
    "    validation_split=0.2,\n",
    "    channel_shift_range=10,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(221, 221), \n",
    "    color_mode = \"rgb\",\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=data_seed,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19372 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(221, 221), \n",
    "    color_mode = \"rgb\",\n",
    "    batch_size= batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=data_seed,\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96947 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(221, 221), \n",
    "    color_mode = \"rgb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(221, 221, 3))\n",
    "# base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(221, 221, 3))\n",
    "# base_model = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(221, 221, 3))\n",
    "#base_model = keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "#base_model = keras.applications.mobilenet.MobileNet(include_top=False, weights='imagenet', input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 221, 221, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 221, 221, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 110, 110, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 110, 110, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 110, 110, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 55, 55, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 55, 55, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 55, 55, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 55, 55, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               47776000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                12850     \n",
      "=================================================================\n",
      "Total params: 48,938,866\n",
      "Trainable params: 48,936,562\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init_weight = keras.initializers.GlorotUniform(seed=49)\n",
    "model = models.Sequential()\n",
    "\n",
    "# CNN\n",
    "# model.add(layers.Conv2D(128, 3, input_shape=(221, 221, 3)))\n",
    "# model.add(layers.MaxPooling2D(3,3))\n",
    "# model.add(layers.Conv2D(32, 3))\n",
    "# model.add(layers.MaxPooling2D(3,3))\n",
    "# model.add(layers.Conv2D(32, 3))\n",
    "# # model.add(layers.MaxPooling2D(3,3))\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# # DNN\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# # model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# # model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(50, activation='softmax'))\n",
    "model.add(Conv2D(64,(3,3),padding='same', input_shape=(221, 221, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#Conv 2\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "#Conv 3\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#Conv 4\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "#Conv 5\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#Conv 6\n",
    "model.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50, activation='softmax'))\n",
    "\n",
    "\n",
    "# callbacks\n",
    "my_callbacks = [\n",
    "    callbacks.EarlyStopping(patience=4, monitor='val_accuracy'),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        verbose=3,\n",
    "        save_best_only=True,\n",
    "        save_weight_only=True,\n",
    "        mode='auto',\n",
    "        period=1\n",
    "    )\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "# opt = SGD(lr=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4848/4848 [==============================] - 828s 170ms/step - loss: 2.4392 - accuracy: 0.3868 - val_loss: 1.4872 - val_accuracy: 0.6052\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60522, saving model to model.h5\n",
      "Epoch 2/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 1.1126 - accuracy: 0.7004 - val_loss: 0.7034 - val_accuracy: 0.8129\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.60522 to 0.81291, saving model to model.h5\n",
      "Epoch 3/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.7418 - accuracy: 0.7960 - val_loss: 1.0625 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.81291\n",
      "Epoch 4/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.5732 - accuracy: 0.8402 - val_loss: 0.3966 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81291 to 0.89762, saving model to model.h5\n",
      "Epoch 5/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.4603 - accuracy: 0.8717 - val_loss: 0.3536 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.89762 to 0.90661, saving model to model.h5\n",
      "Epoch 6/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.3852 - accuracy: 0.8914 - val_loss: 0.2983 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.90661 to 0.92082, saving model to model.h5\n",
      "Epoch 7/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.3289 - accuracy: 0.9064 - val_loss: 0.2487 - val_accuracy: 0.9370\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.92082 to 0.93698, saving model to model.h5\n",
      "Epoch 8/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.2884 - accuracy: 0.9173 - val_loss: 0.2245 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.93698 to 0.94225, saving model to model.h5\n",
      "Epoch 9/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.2528 - accuracy: 0.9267 - val_loss: 0.2304 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.94225\n",
      "Epoch 10/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.2231 - accuracy: 0.9354 - val_loss: 0.2145 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.94225 to 0.94458, saving model to model.h5\n",
      "Epoch 11/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.2078 - accuracy: 0.9395 - val_loss: 0.1781 - val_accuracy: 0.9535\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.94458 to 0.95346, saving model to model.h5\n",
      "Epoch 12/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1859 - accuracy: 0.9458 - val_loss: 0.1988 - val_accuracy: 0.9490\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.95346\n",
      "Epoch 13/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1704 - accuracy: 0.9502 - val_loss: 0.1752 - val_accuracy: 0.9562\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.95346 to 0.95620, saving model to model.h5\n",
      "Epoch 14/100\n",
      "4848/4848 [==============================] - 824s 170ms/step - loss: 0.1602 - accuracy: 0.9523 - val_loss: 0.1673 - val_accuracy: 0.9598\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.95620 to 0.95981, saving model to model.h5\n",
      "Epoch 15/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1459 - accuracy: 0.9564 - val_loss: 0.1806 - val_accuracy: 0.9558\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.95981\n",
      "Epoch 16/100\n",
      "4848/4848 [==============================] - 824s 170ms/step - loss: 0.1375 - accuracy: 0.9591 - val_loss: 0.1691 - val_accuracy: 0.9586\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.95981\n",
      "Epoch 17/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1310 - accuracy: 0.9609 - val_loss: 0.1620 - val_accuracy: 0.9602\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.95981 to 0.96018, saving model to model.h5\n",
      "Epoch 18/100\n",
      "4848/4848 [==============================] - 828s 171ms/step - loss: 0.1225 - accuracy: 0.9634 - val_loss: 0.1335 - val_accuracy: 0.9674\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.96018 to 0.96741, saving model to model.h5\n",
      "Epoch 19/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1152 - accuracy: 0.9655 - val_loss: 0.1440 - val_accuracy: 0.9645\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.96741\n",
      "Epoch 20/100\n",
      "4848/4848 [==============================] - 825s 170ms/step - loss: 0.1088 - accuracy: 0.9670 - val_loss: 0.1567 - val_accuracy: 0.9623\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96741\n",
      "Epoch 21/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.1011 - accuracy: 0.9693 - val_loss: 0.1472 - val_accuracy: 0.9656\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.96741\n",
      "Epoch 22/100\n",
      "4848/4848 [==============================] - 831s 171ms/step - loss: 0.0971 - accuracy: 0.9708 - val_loss: 0.1439 - val_accuracy: 0.9675\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.96741 to 0.96746, saving model to model.h5\n",
      "Epoch 23/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0895 - accuracy: 0.9723 - val_loss: 0.1603 - val_accuracy: 0.9604\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.96746\n",
      "Epoch 24/100\n",
      "4848/4848 [==============================] - 825s 170ms/step - loss: 0.0865 - accuracy: 0.9736 - val_loss: 0.1392 - val_accuracy: 0.9683\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.96746 to 0.96829, saving model to model.h5\n",
      "Epoch 25/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 0.1253 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.96829 to 0.97149, saving model to model.h5\n",
      "Epoch 26/100\n",
      "4848/4848 [==============================] - 829s 171ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.1246 - val_accuracy: 0.9710\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.97149\n",
      "Epoch 27/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0779 - accuracy: 0.9760 - val_loss: 0.1217 - val_accuracy: 0.9721\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.97149 to 0.97206, saving model to model.h5\n",
      "Epoch 28/100\n",
      "4848/4848 [==============================] - 824s 170ms/step - loss: 0.0717 - accuracy: 0.9781 - val_loss: 0.1655 - val_accuracy: 0.9633\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.97206\n",
      "Epoch 29/100\n",
      "4848/4848 [==============================] - 828s 171ms/step - loss: 0.0700 - accuracy: 0.9789 - val_loss: 0.1412 - val_accuracy: 0.9681\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.97206\n",
      "Epoch 30/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0684 - accuracy: 0.9789 - val_loss: 0.1206 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.97206 to 0.97278, saving model to model.h5\n",
      "Epoch 31/100\n",
      "4848/4848 [==============================] - 824s 170ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.1186 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.97278 to 0.97433, saving model to model.h5\n",
      "Epoch 32/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.1245 - val_accuracy: 0.9741\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.97433\n",
      "Epoch 33/100\n",
      "4848/4848 [==============================] - 832s 172ms/step - loss: 0.0607 - accuracy: 0.9812 - val_loss: 0.1311 - val_accuracy: 0.9715\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.97433\n",
      "Epoch 34/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.1188 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.97433 to 0.97459, saving model to model.h5\n",
      "Epoch 35/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.1171 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.97459 to 0.97515, saving model to model.h5\n",
      "Epoch 36/100\n",
      "4848/4848 [==============================] - 828s 171ms/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 0.1313 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.97515\n",
      "Epoch 37/100\n",
      "4848/4848 [==============================] - 825s 170ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.1320 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.97515\n",
      "Epoch 38/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0520 - accuracy: 0.9838 - val_loss: 0.1178 - val_accuracy: 0.9756\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.97515 to 0.97562, saving model to model.h5\n",
      "Epoch 39/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.1275 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.97562\n",
      "Epoch 40/100\n",
      "4848/4848 [==============================] - 829s 171ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.1333 - val_accuracy: 0.9726\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.97562\n",
      "Epoch 41/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0508 - accuracy: 0.9851 - val_loss: 0.1190 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.97562\n",
      "Epoch 42/100\n",
      "4848/4848 [==============================] - 823s 170ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.1150 - val_accuracy: 0.9756\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.97562\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_steps = valid_generator.samples // batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=my_callbacks,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create {ID, filename} dictionary {'1269': '1269.jpg', '3863': '3863.jpg',.....}\n",
    "test_dict = {}\n",
    "for root, dirs, files in os.walk(test_dir):\n",
    "    for filename in files:\n",
    "        test_id, file_ext = os.path.splitext(filename)\n",
    "        test_dict[test_id] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'abraham_grampa_simpson',\n",
       " 1: 'agnes_skinner',\n",
       " 2: 'apu_nahasapeemapetilon',\n",
       " 3: 'barney_gumble',\n",
       " 4: 'bart_simpson',\n",
       " 5: 'brandine_spuckler',\n",
       " 6: 'carl_carlson',\n",
       " 7: 'charles_montgomery_burns',\n",
       " 8: 'chief_wiggum',\n",
       " 9: 'cletus_spuckler',\n",
       " 10: 'comic_book_guy',\n",
       " 11: 'disco_stu',\n",
       " 12: 'dolph_starbeam',\n",
       " 13: 'duff_man',\n",
       " 14: 'edna_krabappel',\n",
       " 15: 'fat_tony',\n",
       " 16: 'gary_chalmers',\n",
       " 17: 'gil',\n",
       " 18: 'groundskeeper_willie',\n",
       " 19: 'homer_simpson',\n",
       " 20: 'jimbo_jones',\n",
       " 21: 'kearney_zzyzwicz',\n",
       " 22: 'kent_brockman',\n",
       " 23: 'krusty_the_clown',\n",
       " 24: 'lenny_leonard',\n",
       " 25: 'lionel_hutz',\n",
       " 26: 'lisa_simpson',\n",
       " 27: 'lunchlady_doris',\n",
       " 28: 'maggie_simpson',\n",
       " 29: 'marge_simpson',\n",
       " 30: 'martin_prince',\n",
       " 31: 'mayor_quimby',\n",
       " 32: 'milhouse_van_houten',\n",
       " 33: 'miss_hoover',\n",
       " 34: 'moe_szyslak',\n",
       " 35: 'ned_flanders',\n",
       " 36: 'nelson_muntz',\n",
       " 37: 'otto_mann',\n",
       " 38: 'patty_bouvier',\n",
       " 39: 'principal_skinner',\n",
       " 40: 'professor_john_frink',\n",
       " 41: 'rainier_wolfcastle',\n",
       " 42: 'ralph_wiggum',\n",
       " 43: 'selma_bouvier',\n",
       " 44: 'sideshow_bob',\n",
       " 45: 'sideshow_mel',\n",
       " 46: 'snake_jailbird',\n",
       " 47: 'timothy_lovejoy',\n",
       " 48: 'troy_mcclure',\n",
       " 49: 'waylon_smithers'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpsons_dict = {}\n",
    "dirs = os.listdir(train_dir)\n",
    "dirs = sorted(dirs)\n",
    "\n",
    "for dir in dirs:\n",
    "    simpsons_dict[dirs.index(dir)] = dir\n",
    "simpsons_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load_img(filename, target_w=150, target_h=150):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (target_w, target_h, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10791: gary_chalmers                 \r"
     ]
    }
   ],
   "source": [
    "# Read images in order and make predictions\n",
    "model = keras.models.load_model('model.h5')\n",
    "results = []\n",
    "\n",
    "for i in range(1, len(test_dict) + 1):\n",
    "    img = load_img(test_dir + \"/\" + test_dict[str(i)], 221, 221)\n",
    "    ret = model.predict(img)\n",
    "    print(\"{:5d}: {:30s}\".format(i, simpsons_dict[np.argmax(ret)]), end=\"\\r\")\n",
    "    results.append(np.argmax(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results in CSV format and upload to Kaggle\n",
    "with open('pred_results.csv', 'w') as f:\n",
    "    f.write('id,character\\n')\n",
    "    for i in range(len(results)):\n",
    "        f.write(str(i+1) + ',' + str(simpsons_dict[results[i]]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='pred_results.csv' target='_blank'>pred_results.csv</a><br>"
      ],
      "text/plain": [
       "/home/jupyter/pred_results.csv"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download your results!\n",
    "from IPython.display import FileLink\n",
    "FileLink('pred_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
